{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene understanding: HOI using 3D skelton and object extraction\n",
    "## 1. Feature extraction\n",
    "### a. Object detection network\n",
    "Goal: bounding box information on the object (which is region of interest)\n",
    "<br>\n",
    "<br>\n",
    "Method: YOLO, Deformable ConvNet (https://arxiv.org/pdf/1703.06211.pdf)\n",
    "<br>\n",
    "<br>\n",
    "Core idea: split into small grid and predict for each grid, then add bounding box onto it.\n",
    "<br>\n",
    "<br>\n",
    "Thought: maybe not use bounding box, but use segmented pixels with a white background?\n",
    "\n",
    "### b. Human Skeleton extraction (tbd)\n",
    "Goal: extract human skeleton of the image\n",
    "<br>\n",
    "<br>\n",
    "Method: OpenPose\n",
    "<br>\n",
    "<br>\n",
    "Thought: they use bounding box of human. Hidden-state of human nodes are extracted feature descriptors bounding box for human. Maybe we can improve it here. \n",
    "\n",
    "### c. ROI feature extraction\n",
    "Goal: extract features -> feature descriptors\n",
    "<br>\n",
    "<br>\n",
    "Method: ResNet-152\n",
    "<br>\n",
    "<br>\n",
    "Thought: There are plenty of feature description method to use. Maybe different descriptors will bring some difference in GNN classification results. (not sure which is better, needs investigation)\n",
    "\n",
    "## 2. Nodes & Edges\n",
    "### a. Nodes from features\n",
    "Goal: Build Nodes with extracted feature descriptor\n",
    "<br>\n",
    "<br>\n",
    "Method: Features of bounding boxes in one frame. Human node size: node_features[i_node, :roi_size], have no idea why it is roi_size, need investigation in the feature extraction pipeline.\n",
    "\n",
    "### b. Edges from features\n",
    "Goal: Build Edges with extracted feature descriptor\n",
    "<br>\n",
    "<br>\n",
    "Method: concatenated bounding box of each human and object. Edge feature size: edge_features[i_human, human_num + i_obj, :], also needs investigation in extraction pipeline, finding out the bouding boxes and other information are saved (Where does roi_size play a role).\n",
    "<br>\n",
    "<br>\n",
    "Thought: I think it contains redundant information (pixels except human and object). \n",
    "\n",
    "### c. Adjacency Matrix\n",
    "Goal: structure of the parse graph. $A∈ [0, 1]^{|V|×|V|}$, V denotes the number of node. It denotes the information flow between nodes of the parse graph, so the structure of the parse graph can be estimated by A. \n",
    "<br>\n",
    "<br>\n",
    "Method: Size of A is determined in the parse_features.py, just a 2D array and not too much to explain.\n",
    "\n",
    "### d. Node labels\n",
    "Goal: predicted labels of each nodes, is result of GNN inference. It is also the thing we used to compute the loss (between predicted node_label and ground-truth node_label)\n",
    "\n",
    "\n",
    "## 3. Graph Neural Network\n",
    "\n",
    "### z. General information about GNN\n",
    "1. resize edge feature size and node feature size into message size, use fully connected layer to convert node size and edge size, just avoid odd number, no idea why to do this. After this FC, use xavier normalization to normalize the weight. (Maybe a drawing helps explaining)\n",
    "2. for each image, for each propagating layer, for each valid node, do such a forward pass of GNN. At last we have the predicted adjacency matrix and the predicted node labels\n",
    "\n",
    "\n",
    "### a. LinkFunction\n",
    "1. General: either 1D convolution (single image) or LSTM (video)\n",
    "\n",
    "### b. MessageFunction\n",
    "\n",
    "### c. UpdateFunction\n",
    "\n",
    "### d. ReadoutFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nodes_num = 10\n",
    "a = np.zeros((nodes_num, nodes_num, 49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
